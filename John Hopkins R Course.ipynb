{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d9b311",
   "metadata": {},
   "source": [
    "# Course 1: Data Science Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab722ef",
   "metadata": {},
   "source": [
    "### Types of Data Science Questions\n",
    "- Descriptive - statistical summary without inference.\n",
    "- Exploratory - correlation, not causation.\n",
    "- Inferential - use small amount of data to generalize info about large group with confidence level.\n",
    "- Predictive analysis - use current and historic data to make predictions.\n",
    "- Causal analysis** - what happens to one variable when we manipulate another.\n",
    "- Mechanistic analysis - exact change in one variable by change of another.!\n",
    "\n",
    "### Experimental design\n",
    "- Formulate question\n",
    "- Design experiment\n",
    "- Identify problems\n",
    "- Collect data.\n",
    "\n",
    "### Big data\n",
    "- Volume\n",
    "- Velocity\n",
    "- Variety\n",
    "\n",
    "\n",
    "### Linking R Studio and Github\n",
    "- R studio > Tools > Global Options > Git/SVN (ensure the git directory path is correct) >  Click create RSA key >  Click view public key and copy it > Login to Github > settings > SSH and GPG Keys > New key > paste the public key in key box\n",
    "\n",
    "- Create a new repository > copy the URL > Create new project in R studio > Version control > Git > paste repository URL, name, local location.\n",
    "\n",
    "- Create a script > Environment > Git select the script to stage your change > click commit > the new window will show the changes in the lower quadrant, commit message in upper left > commit and close > Push your changes > check at Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b632c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Installing Packages\n",
    "install.packages(\"package name\")\n",
    "\n",
    "#What packages are installed\n",
    "installed.packages()\n",
    "library()\n",
    "\n",
    "#Updating packages\n",
    "update.packages()\n",
    "\n",
    "#Unloading packages\n",
    "detach()\n",
    "\n",
    "#Uninstalling packages\n",
    "remove.packages(\"package name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483c86e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Getting help\n",
    "\n",
    "help(package = \"ggplot2\")\n",
    "browseVignettes(\"ggplot2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e531f",
   "metadata": {},
   "source": [
    "# Course 2: R Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f48934",
   "metadata": {},
   "source": [
    "## R Nuts and Bolts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5c302",
   "metadata": {},
   "source": [
    "### 5 types of objects\n",
    "\n",
    "- Character\n",
    "- Numeric\n",
    "- Integer\n",
    "- Complex\n",
    "- Logical (boolean)\n",
    "\n",
    "### Data Types\n",
    "- Vectors can only contain objects of same class - just integer, or just text and so on. If we put different class of objects, R will convert them to one.\n",
    "\n",
    "- Lists can contain objects of different classes.\n",
    "- Matrix in R is filled column wise. It's written with number of rows first, and then number of columns.\n",
    "- Factors is used for coded numbers - 1 for Female and 2 for Male etc.\n",
    "- Data frame stores tabular data.\n",
    "X <- data.frame(foo = 1:4, bar = c(T,T,F,F))\n",
    "- Objects have attributes - class, dimension, length.\n",
    "- Mathematically problematic case is NAN, usual missing value is NA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7b75e",
   "metadata": {},
   "source": [
    "### Reading data\n",
    "\n",
    "#good for moderate sized data, these functions can automatically figure out data types columns etc. (though mentioning them can make the functions faster)\n",
    "read.table()\n",
    "read.csv()\n",
    "\n",
    "For reading large data, read help page of read.table, make rough calculation of needed memory to load the data\n",
    "Set comment.char = \"\" if there are no comment lines in your data.\n",
    "If you don't specify what class types are, R will take resource and time to figure it out.\n",
    "For big data, you should specify class type.\n",
    "colClasses = \"numeric\" sets all class types of the data as Numeric.\n",
    "nrows = 100 loads first 100 rows, and you can check and fix what data classes are from them.\n",
    "sapply(dataname, class) figures the class out, and you can apply the classes with colClasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b42adc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Connection\n",
    "\n",
    "#r is for reading, w is for writing, a is for appending.\n",
    "con <- file(\"temp.txt\", \"r\") # creates connection to the text file temp.txt.\n",
    "data <- read.csv(con) # reads data from the connection\n",
    "close(con) # closes the connection.\n",
    "\n",
    "#The code above does the same as\n",
    "read.csv(\"temp.txt\") # but connections helps at times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb391aea",
   "metadata": {},
   "source": [
    "### Sub setting\n",
    "\n",
    "\"[\" returns objects of same class - subsetting vector will return vector, same for list and so on. It can be used to get more than one element of the object.\n",
    "\n",
    "\"[[\" returns single object form list or data frame. It returns a single element, and thus the class of returned object depends on the specific elemnt it returns.\n",
    "\n",
    "\"$\" returns objects from list or data frame by name. For example it can return specific column.\n",
    "\n",
    "For sub-setting from a matrix x as vector,\n",
    "\n",
    "x[1,2] returns value of first row, second column.\n",
    "x[1,] returns all from first row, x[,1] returns all from second column.\n",
    "x[1,2, drop = FALSE] returns matrix instead of vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab539127",
   "metadata": {},
   "source": [
    "### Subsetting from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ec063",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x <- c(\"a\", \"b\", \"c\", \"c\", \"d\", \"a\")\n",
    "\n",
    "#use of numeric index\n",
    "x[1]\n",
    "x[2]\n",
    "x[1:4]\n",
    "\n",
    "\n",
    "#logical index\n",
    "x[x > \"a\"] #a is of lowest order\n",
    "u <- x > \"a\"\n",
    "u #returns elements that are greater than a\n",
    "\n",
    "\n",
    "#subsetting lists\n",
    "x <- list(foo = 1:4, bar = .6) #first element is a sequence, second element is a number\n",
    "x[1] #by using single bracket, we get back a list from the list\n",
    "x[[1]] #by using double bracket, we get back just a sequence, not a list\n",
    "\n",
    "\n",
    "x$bar #subsetting by name, returns a single number\n",
    "x[[\"bar\"]] #searching by string, returns a single number\n",
    "x[\"bar\"] #searching by string, returns a list with 1 value\n",
    "\n",
    "\n",
    "#subsetting multiple elements by using single bracket \"[]\"\n",
    "x <- list(foo = 1:4, bar = .6, baz = \"hello\") #list from which we want to subset\n",
    "x[c(1,3)] #passing a vector of indices we want to subset, which returns foo and baz\n",
    "#we can't use \"[[]]\" or \"$\" if we want to extract multiple elements of list\n",
    "\n",
    "\n",
    "#\"[[]]\"\" can be used to index a list with computer index\n",
    "x <- list(foo = 1:4, bar = .6, baz = \"hello\") #list from which we want to subset\n",
    "name <- \"foo\"\n",
    "x[[name]] #computed index for 'foo', returns value of foo\n",
    "x$name #error: \"name\" field doesn't exist in the original list\n",
    "x$foo #returns value of \"foo\", as foo\" field exists\n",
    "\n",
    "\n",
    "#\"[[]]\" can take an integer sequence\n",
    "x <- list(a = list(10, 12, 14), b=(3.14, 2,81)) #making a nested list.\n",
    "#now, lets assume we want to extract 14. This is the 3rd element of the first element a!\n",
    "x[[c(1,3)]]\n",
    "#or\n",
    "x[[1]][[3]] #returns 14\n",
    "\n",
    "#similarly\n",
    "x[c(2,1)] #returns 3.14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2cfe4f",
   "metadata": {},
   "source": [
    "### Subsetting from matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e483f7ed",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>3</td><td>5</td></tr>\n",
       "\t<tr><td>2</td><td>4</td><td>6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lll}\n",
       "\t 1 & 3 & 5\\\\\n",
       "\t 2 & 4 & 6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 | 3 | 5 |\n",
       "| 2 | 4 | 6 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2] [,3]\n",
       "[1,] 1    3    5   \n",
       "[2,] 2    4    6   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- matrix(1:6, 2, 3) #matrix is written by nrow first, and it fills clumns first\n",
    "x[1, 2] #subsetting from matrix: row index, column index\n",
    "\n",
    "#subsetting multiple values\n",
    "x[1,] #all from first row\n",
    "x[,2] #all from second column\n",
    "\n",
    "#Usually \"[]\" returns element of same class, but if we subset one element from matrix, we'll get a vector of length 1 rather than a 1*1 matrix. This behavior can be turned off by setting drop = FALSE.\n",
    "x <- matrix(1:6, 2, 3)\n",
    "x[1, 2] #returns vector\n",
    "x[1, 2, drop = FALSE] #returns a 1*1 matrix\n",
    "x[1, , drop = FALSE] #returns matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65586ca5",
   "metadata": {},
   "source": [
    "### Partial Matching\n",
    "\n",
    "If an element name is aabbcc, x$a will return the elements. [[\"a\"]] won't work, [[\"a\", exact = FLASE]] will."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7614b5",
   "metadata": {},
   "source": [
    "### Removing NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c5e3e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "X <- c(1,2,NA,4,NA)\n",
    "Bad <- is.na(x)\n",
    "x[!Bad]\n",
    "\n",
    "\n",
    "# Removing rows of df with NA values\n",
    "airquality[1:6,] # Shows first 6 rows and all columns of airquality data frame.\n",
    "Good <- complete.cases(airquality)\n",
    "airquality[good, ][1:6, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115aee2b",
   "metadata": {},
   "source": [
    "### Vectorized operations\n",
    "If we add 2 vectors, the equivalent elements will be added.\n",
    "Same goes for multiplying or dividing by a number.\n",
    "Same goes for matrix.\n",
    "\n",
    "X * X returns element wise multiplication.\n",
    "X %*% Y returns true matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f73b0d",
   "metadata": {},
   "source": [
    "## Control Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356c367",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Control structure\n",
    "#If, else if, else; for; while (loop while a condition is true); repeat (infinite loop); break; next (skip an iteration of a loop), return (exit a function).\n",
    "\n",
    "for(i in 1:10){\n",
    "    Print(i)}\n",
    "\n",
    "x <- matrix(1:6, 2, 3)\n",
    "\n",
    "for(i in seq_len(nrow(x))){\n",
    "    for(j in seq_len(ncol(x))){\n",
    "        print(x[I , j])}}\n",
    "\n",
    "count <- 0\n",
    "while(count <10){\n",
    "    print(count)\n",
    "    count <- count+1}\n",
    "\n",
    "z <- 5\n",
    "while(z >= 3 && z <= 10){\n",
    "    print(z)\n",
    "    coin <- rbinom(1,1,.5)\n",
    "    if(coin == 1){\n",
    "        z <- z+1}\n",
    "    else{\n",
    "        z <- z-1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11580e",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Functions can be passed as arguments in other functions. They can be nested inside other functions.\n",
    "\n",
    "#### Function Arguments  \n",
    "*Positional Arguments*: If we pass function argument values with argument name (e.g. Data = myData), we'll able to put the argument outside official order. If we don't name the arguments, we'll have to put it in official order.  \n",
    "It also allows us to skip default arguments, and name the argument we want to change.\n",
    "\n",
    "#### Lazy Evaluation\n",
    "If we don't input values of all the arguments, it'll evaluate arguments when needed.  \n",
    "\n",
    "#### The \"...\" Argument\n",
    "... can be used to pass default arguments while extending another function. It's also used when the number of arguments can't be known in advanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c1268",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# This function adds two user specified number\n",
    "\n",
    "add2 <- function(x,y){\n",
    "  x+y\n",
    "}\n",
    "\n",
    "# The function checks which values of input are greater than user specified value n\n",
    "# Here, 10 is taken as default value if user doesn't specify a value.\n",
    "\n",
    "aboven <- function(x,n = 10){\n",
    "  results <- x > n\n",
    "  x[results]\n",
    "}\n",
    "\n",
    "columnmean <- function(y, removeNA= TRUE){  #RemoveNA = TRUE skips NA values from calcuation\n",
    "  nc <- ncol(y)         #number of columns\n",
    "  means <- numeric(nc)  #empty vector that will hold mean values of columns\n",
    "  for(i in 1:nc){\n",
    "    means[i] <- mean(y[,i], na.rm = removeNA) #take all rows of ith column, calculate\n",
    "    # mean, and assign the value in the ith position of means vector\n",
    "  }\n",
    "  means\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefa38d",
   "metadata": {},
   "source": [
    "### Date and Time  \n",
    "Date is represented by **Date** class.  \n",
    "Time is represented by POSIXct (stores time as seconds since base date, appropriate for use in dataframe), or POSIXlt class (stores much more info - day of week, month, year etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1c9f6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x <- Sys.time()\n",
    "p <- as.POSIXct(x)\n",
    "unclass(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c778d",
   "metadata": {},
   "source": [
    "#### strptime\n",
    "The **strptime** function extracts time info from string (and not other classes like Date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae32db6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "datestring <- c(\"January 10, 2012 10:40\")\n",
    "strptime(datestring, \"%B %d, %Y %H:%M\") #what each symbol means can be found in hlep of strptime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c604e3d",
   "metadata": {},
   "source": [
    "### Loop Function  \n",
    "\n",
    "lapply: Loop over a list and evaluate a function on each element  \n",
    "sapply: same as lapply, but to simplify the results  \n",
    "mapply: multivariate version of lapply.  \n",
    "\n",
    "Split is often used with lapply.  \n",
    "\n",
    "#### lapply  \n",
    "\n",
    "    \n",
    "lapply returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0f3d5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# function(list, function, ...)\n",
    "# func <- match.function()\n",
    "# if (!is.vector(X) || is.object(X)){\n",
    "#     X <- as.list(X)\n",
    "#     .Internal(lapply(X,func))}\n",
    "\n",
    "\n",
    "x <- list(a= 1:5, b=rnorm(10))\n",
    "lapply(x, mean)   #lapply went over all values of a and b, and returned single mean value\n",
    "\n",
    "x <- 1:4\n",
    "lapply(x,runif) #loops over the list, given 1 rand uniform vector for 1, 2 for 2 and so on.\n",
    "\n",
    "#we can pass extra arguments of the function in lapply\n",
    "x <- 1:4\n",
    "lapply(x, runif, min = 0, max = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa5a8c",
   "metadata": {},
   "source": [
    "### Anonymous function with lapply  \n",
    "We can define functions inside lapply that only performs inside the lapply.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6e6ff",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x <- list(a = matrix(1:4,2,2), b = matrix(1:6, 3, 2)) # creating list of 2 matrix\n",
    "lapply(x, function(elt) elt[,1]) #function that extracts first column, only lives inside this lapply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1922951",
   "metadata": {},
   "source": [
    "### sapply  \n",
    "sapply works like lapply, but it doesn't always return a list. If the results contain single value for all places, it'll return vector. If it returns vector of same number of values for all, it'll return matrix.  \n",
    "\n",
    "### apply  \n",
    "apply is used for multidimensional array (e.g. 2 dimensional matrix). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e12ace",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "a <- matrix(rnorm(50),10, 5)\n",
    "b <- apply(a, 2, mean) # It'll return a vector of length 5, that has the mean of each columns. 2 is the second dimension (columns), and it colapses first dimension.\n",
    "\n",
    "c <- apply(a, 1, sum) # this preserves rows, and collapses columns.\n",
    "\n",
    "#But it's better to use optimised functions for sum and mean operations\n",
    "\n",
    "# rowSums = apply(x,1, sum)\n",
    "# rowMeans = apply(x, 1, mean)\n",
    "# colSums = apply(x, 2, sum)\n",
    "# colMeans = apply(x, 2, mean)\n",
    "\n",
    "d <- matrix(rnorm(50), 5, 10)\n",
    "e <- apply(d, 1, quantile, probs = c(.25, .75)) #we need to specify 25th and 75th percentile for quantile function, it'll calculate the percentiles over each row. It'll collapse the columns, and return 2 row, 5 column (for the two results against each row) matrix.\n",
    "\n",
    "f <- array(rnorm(2 * 2 * 5), c(2, 2, 5))\n",
    "g <- apply(f, c(1,2), mean) #Here, we're preserving 1st and 2nd dimensions, but collapsing the 3rd. This'll return a mean matrix.\n",
    "\n",
    "h <- rowMeans(f, dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211155c4",
   "metadata": {},
   "source": [
    "### mapply  \n",
    "If we need to apply different arguments to different lists, then we'll have to use for loop. But we can also use Multivariate apply or mapply - can apply a function to multiple lists in parallel. The number of arguments needs to be at least equal to number of objects passed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b4265",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "i <- list(rep(1,4), rep(2,3), rep(3,2), rep(4,1))\n",
    "j <- mapply(rep, 1:4, 4:1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c49e72f",
   "metadata": {},
   "source": [
    "### tapply  \n",
    "tapply(vector, index, FUN, ..., simplify = TRUE)  \n",
    "Applies function over subset of a vector. For example, we can calculate summary statistics (mean, standard deviation etc.) of a group of a vector.  \n",
    "It takes a vector, another vector of same length that identifies what groups does the elements of initial vector belongs to. Then the function we want to apply, the other arguments \"...\", lastly simplify like sapply or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e3193",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "k <- c(rnorm(10), runif(10), rnorm(10,1)) # 10 normal random variables, 10 uniform random variables, 10 normal random variables with mean 1.\n",
    "\n",
    "l <- gl(3,10) #factor vector with 3 levels that's gonna repeat 10 times.\n",
    "\n",
    "m <- tapply(k, l, mean, simplify = FALSE) #if we keep simplify as FALSE, we'll get list of 3 elements, where each element is the mean of the subgroup.\n",
    "\n",
    "n <- tapply(k, l, range) # range returns two observation for each group - the min and the max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ecbf31",
   "metadata": {},
   "source": [
    "### Split  \n",
    "split takes a vector and factor vector like tapply, but instead of applying a function, it splits the initial vector among the groups. We can then apply lapply or sapply on those groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45863af",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "k <- c(rnorm(10), runif(10), rnorm(10,1)) # 10 normal random variables, 10 uniform random variables, 10 normal random variables with mean 1.\n",
    "\n",
    "l <- gl(3,10) #factor vector with 3 levels that's gonna repeat 10 times.\n",
    "\n",
    "o <- split(k,l)\n",
    "\n",
    "p <- lapply(split(k,l ), mean)\n",
    "\n",
    "library(datasets) #library for data sets\n",
    "\n",
    "q <- head(airquality) #loading first few rows of air quality data\n",
    "\n",
    "#Now, we want to split the data into months (each month has about 3o observations), and then calculate mean of each month.\n",
    "\n",
    "r <- split(airquality, airquality$Month) #split the dataframe into months. Since the data is arranged in some specific months, we can use the value to group data.\n",
    "\n",
    "s <- lapply(r, function(x) colMeans(x[c(\"Ozone\", \"Solar.R\", \"Wind\")])) #The anonymous function will calculate mean of Ozone, Solar radiation and Wind columns.\n",
    "\n",
    "t <- sapply(r, function(x) colMeans(x[, c(\"Ozone\", \"Solar.R\", \"Wind\")], na.rm = TRUE)) #If we apply sapply instead of lapply, we'll get a matrix back as the result elements are of same length\n",
    "\n",
    "#Multi-level split\n",
    "u <- rnorm(10)\n",
    "f1 <- gl(2, 5)\n",
    "f2 <- gl(5, 2)\n",
    "\n",
    "v <- interaction(f1, f2) #by concatenating the two filters, we'll have 10 levels\n",
    "\n",
    "w1 <- str(split(u, list(f1, f2))) #this'll split the data into 10 different levels. I don't need to pass interaction function for it to work. Multiple filters can indicate teen-male, middle aged-female etc.\n",
    "\n",
    "w2 <- str(split(u, list(f1, f2), drop = TRUE)) #drop = TRUE drops empty levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283835ed",
   "metadata": {},
   "source": [
    "## Debugging  \n",
    "**Message**: notification, execution continues.\n",
    "**Warning**: indication that something is wrong but not fatal. Execution continues.\n",
    "**Error**: fatal problem notification, execution stops.\n",
    "**Condition**: programmer created notification that something unexpected can occur.\n",
    "\n",
    "### Questions to ask if something's wrong  \n",
    "- What was your actual input? How did you call the function?  \n",
    "- What were you expecting? Output, messages, other results?  \n",
    "- What did you get?  \n",
    "- How does what you get differ from what you were expecting?  \n",
    "- Can you reproduce the problem exactly?  \n",
    "\n",
    "\n",
    "### Debugging tools in R\n",
    "**Traceback**: points out the function call stack after an error occurs.  \n",
    "**Debug**: flags a function for \"debug\", executes one line at a time.  \n",
    "**browser**: suspends the execution of a function wherever it is called and puts the function in debug mode.  \n",
    "**Trace**: allows you to insert debugging code into a function a specific places. Usually done on other's code.  \n",
    "**Recover**: allows you to modify the error behavior so that you can browse the function call stack.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6d453",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mean(x)\n",
    "traceback() #where the error occurred. need to call immediately after error\n",
    "\n",
    "lm(y-x)\n",
    "traceback()\n",
    "\n",
    "debug(lm)\n",
    "lm(y-x) #it'll create an environment with only lm elements, show entire code of lm, and by pressing n+enter you'll be able to execute one line at a time.\n",
    "\n",
    "options(error=recover)\n",
    "read.csv(\"nosuchfile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aa7a82",
   "metadata": {},
   "source": [
    "## str function\n",
    "Short for structure. It's a diagnostic function, an one liner alternative to summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d398e",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "str(lm)\n",
    "\n",
    "x <- rnorm(100, 2, 4)\n",
    "summary(x)\n",
    "str(x)\n",
    "\n",
    "library(datasets)\n",
    "head(airquality)\n",
    "str(airquality)\n",
    "\n",
    "m <- matrix(rnorm(100), 10, 10)\n",
    "m\n",
    "str(m)\n",
    "\n",
    "s <- split(airquality, airquality$Month)\n",
    "str(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca7c04",
   "metadata": {},
   "source": [
    "## Generating Random Numbers\n",
    "\n",
    "rnorm generates random normal variates given mean and std. dev.\n",
    "\n",
    "dnorm: evaluate normal probability density (given mean and std. dev.) at a point.\n",
    "\n",
    "pnorm: evaluate the cumulative distribution function for normal distribution.\n",
    "\n",
    "rpois: generate random Poisson variates with given rate.\n",
    "\n",
    "Every distribution has 4 functions -\n",
    "d for density\n",
    "r for random number generation\n",
    "p for cumulative distribution\n",
    "q for quantile function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc42e7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#set.seed repeats the random numbers generated previously\n",
    "set.seed(1)\n",
    "a <- rnorm(5)\n",
    "\n",
    "b <- rnorm(5)\n",
    "\n",
    "set.seed(1)\n",
    "c <- rnorm(5)\n",
    "\n",
    "a\n",
    "b\n",
    "c\n",
    "\n",
    "d <- rpois(10,1) #generate 10 integer poisson data, with roughly mean 1\n",
    "e <- rpois(10,10) #generate 10 integer poisson data, with roughly mean 10\n",
    "\n",
    "f <- ppois(2,2) #probability of getting less than 2 if mean is set to 2\n",
    "g <- ppois(4, 2) #probability of getting less than 4 if mean is set to 2\n",
    "\n",
    "d\n",
    "e\n",
    "f\n",
    "g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b0be8",
   "metadata": {},
   "source": [
    "## Simulating Linear Model\n",
    "\n",
    "We can simulate value from a model (e.g. linear model).\n",
    "\n",
    "For linear model, we can consider\n",
    "y = mx + c + epsilon\n",
    "where epsilon is noise value with given mean and std. dev.\n",
    "\n",
    "Now, we might need count (integer) variable instead of continuous variable. The error distribution is going to be Poisson distribution.\n",
    "\n",
    "## For Poisson model\n",
    "Y ~ Poisson(mu)\n",
    "log mu = mx + c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc4cf8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(20) #for reproducability\n",
    "a <- rnorm(100)\n",
    "b <- rnorm(100, 0, 2) #mean of epsilon is 0, std. dev. is 2\n",
    "c <- .5 + 2 * a + b #c = .5, m = 2\n",
    "\n",
    "summary(c)\n",
    "plot(a,c)\n",
    "\n",
    "#considering x as binary variable (data against male-female)\n",
    "set.seed(10) #for reproducability\n",
    "d <- rbinom(100, 1, .5)\n",
    "e <- rnorm(100, 0, 2) #mean of epsilon is 0, std. dev. is 2\n",
    "f <- .5 + 2 * d + e #c = .5, m = 2\n",
    "\n",
    "summary(f)\n",
    "plot(d,f)\n",
    "\n",
    "#simulating from Poisson model\n",
    "#For g = .5 and h = .3\n",
    "\n",
    "set.seed(1)\n",
    "i <- rnorm(100) #independent variable\n",
    "log.mu <- .5 + .3 * i #log of linear predictor\n",
    "j <- rpois(100, exp(log.mu)) #Expentiate the log to get mean\n",
    "\n",
    "summary (j)\n",
    "plot(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b87335",
   "metadata": {},
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fef52c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "a <- sample(1:10, 4) #sample 4 values from 1 to 10 without replacement\n",
    "a\n",
    "\n",
    "b <- sample(1:10, 4)\n",
    "b\n",
    "\n",
    "c <- sample(letters, 5)\n",
    "c\n",
    "\n",
    "d <- sample(1:10) #1 to 10 in random order\n",
    "d\n",
    "\n",
    "e <- sample (1:10)\n",
    "e\n",
    "\n",
    "f <- sample(1:10, replace = TRUE) #sample with replacement\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9ce2d",
   "metadata": {},
   "source": [
    "## R Profiler\n",
    "\n",
    "R Profiler states why program is taking long time. Useful for large programs.\n",
    "\n",
    "Make it work first, make it readable, only after that optimize.\n",
    "\n",
    "system.time() tells us required time for computation. User time is required CPU time, elapsed time is what you see.\n",
    "\n",
    "Rprof() starts profiler\n",
    "summaryRprof() summarises output from Rprof()\n",
    "we can't use system.time() adn Rprof() together.\n",
    "\n",
    "by.total tells total time spent in function.\n",
    "by.self tells how much time the program spends after substracting time of low level helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f807739",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#elapsed time > user time\n",
    "system.time(readLines(\"http://www.jhsph.edu\")) #as network time adds to elapsed time\n",
    "\n",
    "#elapsed time < user time. Parallel process makes user time twice.\n",
    "hilbert <- function(n){\n",
    "    i <- 1:n\n",
    "    1/outer(i-1,i,\"+\")\n",
    "}\n",
    "x <- hilbert(1000)\n",
    "system.time(svd(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba5c3e",
   "metadata": {},
   "source": [
    "# Course 3: Getting and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21956e58",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688bd94",
   "metadata": {},
   "source": [
    "Raw data > Processing script > Tidy processed data > Analysis > Communication\n",
    "\n",
    "### Components of tidy data\n",
    "\n",
    "Deliveribles\n",
    "1. Raw data\n",
    "2. Tidy data\n",
    "3. Metadata: Code book describing each variable and its values in tidy data set. E.g. unit of a column of tidy data.\n",
    "4. Explicit and exact recipe you used to go from 1 to 2 and 3.\n",
    "\n",
    "Components of tidy data:\n",
    "1. Each variable in 1 column.\n",
    "2. Each observation of that variable in different row.\n",
    "3. One table for each kind of variable.\n",
    "4. Linking column of different tables (keys).\n",
    "5. Having a row with human readable variable names - AgeAtDiagnosis instead of AgeDx.\n",
    "6. In general, data should be saved one file per table.\n",
    "\n",
    "The code book:\n",
    "1. Code book: Each variable and their units\n",
    "2. Summary\n",
    "3. Info about data collection experiment.\n",
    "\n",
    "Instruction list:\n",
    "1. Script that outputs tidy data on input of raw data without any modification requirement.\n",
    "2. Commenting on the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc0982",
   "metadata": {},
   "source": [
    "### Get/set working directory\n",
    "\n",
    "getwd() for getting current directory, setwd() for setting new directory.\n",
    "\n",
    "For windows machines, we need to use back slashes, or c(directory).\n",
    "\n",
    "file.exists(\"directoryName\") searches if any subdirectory with name directoryName exists in the current directory.\n",
    "dir.create(\"directoryName\") creates directory of name directoryName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3c9a2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!file.exists(\"data\")){dir.create(\"data\")} #searches for subdirectory \"data\" in current directory, and creates the subdirectory if it doesn't exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd60c17",
   "metadata": {},
   "source": [
    "download.file() downoads file from internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b94fee",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#fileUrl <- \"https://\"\n",
    "#download.file(fileUrl, destfile = \"./destDirectory/data.csv\", method = \"curl\")\n",
    "#list.files(\"./destDirectory\")\n",
    "\n",
    "#dateDownloaded <- date(), as data changes with date\n",
    "#dateDownloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e514dc",
   "metadata": {},
   "source": [
    "### Loading local flat file\n",
    "\n",
    "#### Reading CSV files\n",
    "read.table() is the most common function. Not the best tool for loading big data. Important parameters include file, header, sep, row.names etc.\n",
    "quote = \"\" means no quotes.\n",
    "na.strings - sets teh character that represents missing values.\n",
    "nrows - how many rows to read.\n",
    "skip - number of lines to skip before starting to read.\n",
    "\n",
    "#### Reading excel files\n",
    "\"xlsx\" library can be used for opening excel files.\n",
    "Parameters of read.xlsx includes sheetIndex, header = TRUE etc, colIndex (e.g. 2:3), rowIndex (e.g. 1:4) for loading specific portion of the files.\n",
    "\n",
    "write.xlsx can be used to write in excel file.\n",
    "read.xlsx2 can be faster than read.xlsx, but it's bit unstable for subset reading.\n",
    "\n",
    "XLConnect is a good library if someone works with loads of excel files.\n",
    "XLConnect vignette: https://cran.r-project.org/web/packages/XLConnect/vignettes/XLConnect.pdf\n",
    "\n",
    "Usually, csv is faster to work with.\n",
    "\n",
    "#### Reading XML data\n",
    "Usually received from structured web data. Two components are Markup and Content.\n",
    "\n",
    "Tags\n",
    "Start tags <section>\n",
    "End tags </section>\n",
    "\n",
    "Attributes\n",
    "<img src=\"jeff.jpg\" alt=\"instructor\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b5b9e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac80831b",
   "metadata": {},
   "source": [
    "## Reading Data from Web\n",
    "\n",
    "### Reading XML data\n",
    "We need XML library.\n",
    "\n",
    "Xpath language is used for extracting xml data. Tutorial - stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be0249",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(XML)\n",
    "fileUrl <- \"http://www.w3schools.com/xml/simple.xml\"\n",
    "doc <- xmlTreeParse(fileUrl, useInternal=TRUE) #this loads the page in memory\n",
    "rootNode <- xmlRoot(doc) #wrapper of entire doc\n",
    "xmlName(rootNode) #get the name out\n",
    "\n",
    "names(rootNode) #tells all the nested elements of doc\n",
    "\n",
    "rootNode[[1]] #first element of rootNode\n",
    "rootNode[[1]][[1]] #first sub component of first element\n",
    "\n",
    "xmlSApply(rootNode, xmlValue) #loop through all values of rootNode, and return xml values of all tags\n",
    "\n",
    "xpathSApply(rootNode,\"//name\",xmlvalue) #returns \"name\" node values\n",
    "xpathSApply(rootNode,\"//price\",xmlvalue) #returns \"price\" node values\n",
    "\n",
    "#if we extract information from html file instead of xml file, we'll use html tree parse instead of xml\n",
    "fileUrl <- \"http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens\"\n",
    "doc <- htmlTreeParse(fileUrl,useInternal=TRUE) #useInternal = TRUE returns all nodes\n",
    "\n",
    "#extracting specific data. For this, we need take a look at source code of page, and decide what node we're interested in.\n",
    "scores <- xpathSApply(doc,\"//li[@class='score']\",xmlValue)\n",
    "teams <- xpathSApply(doc,\"//li[@class='team-name']\",xmlValue)\n",
    "\n",
    "#show the data\n",
    "scores\n",
    "teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1ac6d",
   "metadata": {},
   "source": [
    "### Reading JSON data\n",
    "\n",
    "Organized data structure that is widely used.\n",
    "\n",
    "Good tutorial: r-bloggers.com/new-package-jsonlite-a-smarter-json-encoderdecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40706b3f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Reading JSON data\n",
    "library(jsonlite)\n",
    "jsonData <- fromJSON(\"https://api.github.com/users/jtleek/repos\")\n",
    "names(jsonData) #names of objects and attributes\n",
    "names(jsonData$owner) #attribute info of a specific object\n",
    "jsonData$owner$login #entries of attribute\n",
    "\n",
    "#writing data frames in JSON\n",
    "myjson <- toJSON(iris, pretty=TRUE) #iris is a popular dataset, which'll be converted to JSON. Pretty = TRUE indents the file.\n",
    "cat(myjson) #prints the file\n",
    "\n",
    "iris2 <- fromJSON(myjson)\n",
    "head(iris2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507ab77",
   "metadata": {},
   "source": [
    "### Data.table package\n",
    "\n",
    "Faster and data efficient than data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad32cf9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "DF = data.frame(x=rnorm(9),y=rep(c(\"a\",\"b\",\"c\"),each=3),z=rnorm(9))\n",
    "dfh <- head(DF,3)\n",
    "dfh\n",
    "\n",
    "DT = data.table(x=norm(9),y=rep(c(\"a\",\"b\",\"c\"),each=3),z=rnorm(9))\n",
    "dth <- head(DT,3)\n",
    "dth\n",
    "\n",
    "#summary of data\n",
    "tables()\n",
    "\n",
    "#subsetting rows\n",
    "DT[2,] # select all columns of 2nd row\n",
    "DT[DT$y=\"a\"] #select all data where y = \"a\" - like filter function, but for a column?\n",
    "\n",
    "DT[c(2,3)] #data tables subset rows, the operation will return 2nd and 3rd rows\n",
    "DT[,c(2,3)] #this doesn't return 2nd and 3rd column\n",
    "\n",
    "#Expression in R is a collection of statements enclosed in curley brackets\n",
    "DT[,list(mean(x),sum(z))] #will return mean of x, and sum of z values\n",
    "DT[,table(y)] #returns table of y values - like filter function\n",
    "\n",
    "#adding new columns\n",
    "DT[,w:=z^2] #creates a new column with name w, which includes square of z values - like mutate\n",
    "\n",
    "#Multiple operations\n",
    "DT[,m:= {tmp <- (x+z)}; log2(tmp+5)] #store x+z in temp variable, add 5 and calculate 2 based log, store it in new column m - advanced mutate like\n",
    "\n",
    "#Gouping\n",
    "DT[,a:=x>0] #this'll return a boolean column\n",
    "DT[,b:=mean(x+w),by=a] #this'll calculate mean of x+w when a is TRUE, and apply it in all a=TRUE. It'll also calculate mean of x+w when a is FALSE, and apply it in all a = FALSE.\n",
    "\n",
    "#Special character (e.g. .N)\n",
    "set.seed(123);\n",
    "DT <- data.table(x=sample(letters[1:3], 1E5, TRUE)) #10^5 a, b and cs\n",
    "DT[, .N, by=x] #.N counts the number of times a group (here by x) appears.\n",
    "\n",
    "#Keys: if we define keys, subsetting can be done easily\n",
    "\n",
    "DT <- data.table(x=rep(c(\"a\", \"b\", \"c\"), each=100), y=rnorm(300)) #a table of two variable\n",
    "setkey(DT,x) #set variable x as key\n",
    "DT['a'] #group by the key\n",
    "\n",
    "#Keys to join multiple tables\n",
    "DT1 <- data.table(x=c('a', 'a', 'b', 'dt1'), y=1:4)\n",
    "DT2 <- data.table(x=c('a', 'b', 'dt2'),z=5:7)\n",
    "setkey(DT1, x); setkey(DT2, x)\n",
    "merge(DT1, DT2)\n",
    "\n",
    "#Reading from external source\n",
    "#fread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffd3098",
   "metadata": {},
   "source": [
    "### mySQL\n",
    "Data is structured in databases, each database as many tables, each tables has many fields, many fields has many records.\n",
    "\n",
    "Different tables are connected with keys.\n",
    "\n",
    "First step is to install mySQL from its website. And then installing RMySQL for R.\n",
    "\n",
    "Tutorial for windows install:\n",
    "http://www.ahschulz.de/2013/07/23/installing-rmysql-under-windows/\n",
    "\n",
    "mySQL commands collection:\n",
    "http://www.pantz.org/software/mysql/mysqlcommands.html\n",
    "\n",
    "R commands for mySQL:\n",
    "https://www.r-bloggers.com/2011/08/mysql-and-r/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13a1e2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#loading entire database\n",
    "ucscDb <- dbConnect(MySQL(), user=\"genome\", host=\"genome-mysql.cse.ucsc.edu\") #this will create a connection\n",
    "result <- dbGetQuery(ucscDb,\"show databases;\"); dbDisconnect(ucscDb) #applying query, get data, and disconnect, which should return \"TRUE\"\n",
    "result #shows avaiable databases\n",
    "\n",
    "#Loading specific database\n",
    "hg19 <- dbConnect(MySQL(),user=\"genome\",db=\"hg19\",host=\"genome-mysql.cse.ucsc.edu\") #one particular database \"hg19\"\n",
    "result <- dbListTables(hg19) #there are multiple tables under this database\n",
    "length(allTables) #number of tables\n",
    "allTables[1:5] #first 5 tables\n",
    "\n",
    "#loading specific table\n",
    "dbListFields(hg19,\"affyU133Plus2\") #loading one table, returns fields list. hg19 was the connection to the table in database.\n",
    "\n",
    "dbGetQuery(hg19,\"select count(*) from affyU133Plus2\") #select rows of 1 field with mySQL query command\n",
    "\n",
    "#read from table\n",
    "affyData <- dbReadTable(hg19,\"affyU133Plus2\") #read table\n",
    "head(affyData) #first 6 rows\n",
    "\n",
    "#reading specific amount of data\n",
    "query <- dbSendQuery(hg19, \"select * from affyU133Plus2 where misMatches between 1 and 3\") #Creates connection to specific data (here against specific values of a specific field), as entire data can be too big\n",
    "affyMis <- fetch(query); quantile(affyMis$misMatches) #tells us about the sample we collected above\n",
    "affyMisSmall <- fetch(query,n=10); dbClearResult(query) #loading small amount of data. We need to clear query after fetching data, which'll return \"TRUE\".\n",
    "dim(affyMisSmall) #returns dimension of the data\n",
    "\n",
    "#Remember to close the connection\n",
    "dbDisconnect(hg19) #should return \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec5031",
   "metadata": {},
   "source": [
    "### Reading from HDF5\n",
    "Used to store large hierarchical data.\n",
    "\n",
    "The R package is installed through bioconductor.\n",
    "\n",
    "Tutorial:\n",
    "https://www.bioconductor.org/packages/release/bioc/manuals/rhdf5/man/rhdf5.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d821962",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#installing hdf5 R library\n",
    "source(\"http://bioconductor.org/biocLite.R\")\n",
    "biocLite(\"rhdf5\")\n",
    "\n",
    "library(rhdf5) #loading library\n",
    "created = h5createFile(\"example.h5\") #creading hdf5 file\n",
    "\n",
    "#creating hierarchical group\n",
    "created = h5createGroup(\"example.h5\", \"foo\")\n",
    "created = h5createGroup(\"example.h5\", \"baa\")\n",
    "created = h5createGroup(\"example.h5\", \"foo/foobaa\")\n",
    "h5ls(\"example.h5\")\n",
    "\n",
    "#writing to hdf5\n",
    "A = matrix(1:10,nr=5,nc=2) #creating data\n",
    "h5write(A,\"example.h5\",\"foo/A\") #example.h5 is the file, foo/A is the group\n",
    "B = array(seq(0.1,2.0,by=0.1),dim=c(5,2,2)) #we can also write multi dimensional array\n",
    "attr(B,\"scale\") <- \"liter\" #we can add attribute\n",
    "h5write(B,\"example.h5\",\"foo/foobaa/B\") #we can add teh array to a particular sub group\n",
    "h5ls(\"example.h5\") #what are the data\n",
    "\n",
    "#writing a data set\n",
    "df = data.frame(1L:5L,seq(0,1,length.out=5)\n",
    "               c(\"ab\",\"cde\",\"fghi\",\"a\",\"s\"),stringAsFactors = FALSE)\n",
    "h5write(df,\"example.h5\",\"df\") #writing data frame directly in top level group\n",
    "h5ls(example.h5) #data summary\n",
    "\n",
    "#reading data\n",
    "readA = h5read(\"example.h5\",\"foo/A\") #reading data\n",
    "readB = h5read(\"example.h5\",\"foo/foobaa/B\") #reading sub dataset\n",
    "readdf = h5read(\"example.h5\",\"df\") #reading from top level group\n",
    "readA\n",
    "\n",
    "#writing and reading in chunks\n",
    "h5write(c(12, 13, 14),\"example.h5\",\"foo/A\",index=list(1:3,1)) #in the mentioned file (example.h5,foo/A), write to the first 1st 3 rows and 1st column (1:3,1) specified values (12, 13, 14)\n",
    "h5read(\"example.h5\",\"foo/A\") #it's also possible to read specif index in read also like above (shown in the previous line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c904b9",
   "metadata": {},
   "source": [
    "### Reading data from the web\n",
    "\n",
    "**Webscraping**\n",
    "Programatically extracting data from HTML code of website.\n",
    "\n",
    "Interesting story:\n",
    "https://www.theatlantic.com/technology/archive/2014/01/how-netflix-reverse-engineered-hollywood/282679/\n",
    "\n",
    "Searching web scrapping in R-bloggers\n",
    "httr help file is helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d4872",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "connec = url(\"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en\") #connect with site\n",
    "htmlCode = readLine(connec) #Read data\n",
    "close(connec) #close connection after usage\n",
    "htmlCode #the data collected\n",
    "\n",
    "#Getting readable data from site using XML library\n",
    "library(XML)\n",
    "url <- \"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en\"\n",
    "html <- htmlTreeParse(url, useInternalNodes=T)\n",
    "\n",
    "xpathSApply(html,\"//title\", xmlValue)\n",
    "xpathSApply(html,\"//td[@id='col-citedby']\", xmlValue)\n",
    "\n",
    "#Using GET from HTTR package\n",
    "library(httr); html2 = GET(url)\n",
    "content2 = content(html2,as=\"text\")\n",
    "parseHtml = htmlParse(content2, asText = TRUE)\n",
    "xpathSApply(parseHrml, \"//title\", xmlValue)\n",
    "\n",
    "#Accessing websites with passwords\n",
    "pg1 = GET(\"http://httpbin.org/basic-auth/user/passwd\")\n",
    "pg1 #will ask for password with status 401\n",
    "\n",
    "pg2 = GET(\"http://httpbin.org/basic-auth/user/passwd\",\n",
    "         authenticate(\"user\",\"passwd\")) #test website, username is \"user\" and password is \"passwd\"\n",
    "pg2 #will return status 200\n",
    "\n",
    "#Using handles, to save authentication across multiple sites\n",
    "google = handle(\"http://google.com\")\n",
    "pg1 = GET(handle=google,path=\"/\")\n",
    "pg2 = GET(handle=google, path=\"search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b769cd28",
   "metadata": {},
   "source": [
    "### Reading form APIs\n",
    "For accessing Twitter data, we need to create an application.\n",
    "In general, API requrie reading of documentation.\n",
    "\n",
    "HTTR works well with FB, Google, Twitter, Github etc.\n",
    "HTTR demos in Github can be helpful.\n",
    "\n",
    "(You had already done this homework in CS50!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667592f6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "myapp = oauth_app(\"twitter\", key=\"yourConsumerKeyHere\", secret=\"yourConsumerSecretHere\") #pass your credential\n",
    "sig = sign_oauth1.0(myapp, token=\"yourTokenHere\", token_secret=\"yourTokenSecretHere\") #generate authentication\n",
    "homeTL = GET(\"https://api.twitter.com/1.1/statuses/home_timeline.json\",sig) #what data I want to get by passing the authentication of previous line.\n",
    "                                                                            #The URL is found at Twitter documentation > GET statuses/home_timeline > resource URL\n",
    "\n",
    "json1 = content(homeTL) #returns structured R object (which is hard to read)\n",
    "json2 = jsonlite::fromJSON(toJSON(json1)) #from JSON reformats it, jsonlite converts it to data frame\n",
    "json2[1,1:4] #look at first row of first 4 columns of the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08610ca9",
   "metadata": {},
   "source": [
    "### R Package for almost all needs\n",
    "\n",
    "file - open a connection to local text file.\n",
    "url - open a connection to URL\n",
    "gzfile - open a connection to a .gz file\n",
    "bzfile - open a connection to a .bz2 file\n",
    "?connections for more info\n",
    "\n",
    "**It's important to close connection after use**\n",
    "\n",
    "Foreign package\n",
    "read.foo: read.dta(stata), read.spss(SPSS)\n",
    "\n",
    "It's possible to read image data, GIS data (rdgal, rgeos, raster), music (tuneR, seewave).\n",
    "\n",
    "You can find package jusy by googling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c4917",
   "metadata": {},
   "source": [
    "## Raw to Tidy Data***\n",
    "### Subsetting data\n",
    "Lecture notes: www.biostat.jhsph.edu/~ajaffe/lec_winterR/Lecture%202.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184f07c",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Subsetting\n",
    "set.seed(13435) #for reproducable sampling\n",
    "x <- data.frame(\"var1\"=sample(1:5), \"var2\"=sample(6:10), \"var3\"=sample(11:15)) #has 3 variables, each variable has random sequence of 5 values\n",
    "x <- x[sample(1:5),];x$var2[c(1,3)]=NA #now random sample from first 5 rows and all 3 columns, and make some values NA\n",
    "x\n",
    "\n",
    "#Row and column wise subsetting. Remember \"[]\" is used to subset multiple values.\n",
    "x[,1] #Select first column\n",
    "x[,\"var1\"] #select all rows of var1 column\n",
    "x[1:2, \"var2\"] #select first 2 rows of var2 column\n",
    "\n",
    "#Logicals, ands and ors\n",
    "x[(x$var1 <= 3 & x$var3 > 11),] #select the rows of all columns, where value of var1 is less than-equal to 3 and value of var3 is greater than 11\n",
    "x[(x$var1 <= 3 | x$var3 > 15),] #select the rows of all columns, where value of var1 is less than-equal to 3 or value of var3 is greater than 15\n",
    "\n",
    "#Dealing with missing values\n",
    "x[which(x$var2 >= 6),] #select all values where var2 is greater than-equal to 6, which'll not include NA values of var2. And since NA only exist in var2, the entire data frame will be NA free.\n",
    "\n",
    "#sorting\n",
    "sort(x$var1) #sort var1 values in ascending order\n",
    "sort(x$var1, decreasign = TRUE) #sort var1 in descending order\n",
    "sort(x$var2, na.last=TRUE) #put NA at last\n",
    "x[order(x$var1),] #order by a column value - apply ordering on var1 first, then use the ordering in the data frame\n",
    "x[order(x$var1,x$var3),] #it'll order the data by var1, and then if there are multiple same values of var1, it'll order in those by var3 values\n",
    "\n",
    "##Ordering with plyr\n",
    "#library(plyr)\n",
    "#arrange(x,var1) #pass data frame, variable - and it'll sort the data frame by that variables\n",
    "\n",
    "#arrange(X,desc(var1)) #data frame, variable wrapped in desc() for descending order\n",
    "\n",
    "#Adding new column\n",
    "x$var4 <- rnorm(5)\n",
    "\n",
    "#Adding rows and columns\n",
    "y <- cbind(x,rnorm(5)) #column bind, add a new column of 5 normal variable at right-most side\n",
    "y <- cbind(rnorm(5), x) #column bind in leftmost side of x\n",
    "y <- rbind(x,rnorm(3)) #bind a row at last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dbde3f",
   "metadata": {},
   "source": [
    "### Summarizing data - Very Useful\n",
    "In order to clean data, we need to look at the summaries, weirdness of data.\n",
    "\n",
    "Example, restaurant data of Baltimore city government."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd811c40",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!file.exists(\"./data\")){dir.create(\"./data\")} #if directory doesn't exist, create a directory\n",
    "fileURL <- \"file URL.csv?accessType=DOWNLOAD\" #check the URL, create connection\n",
    "download.file(fileUrl,destfile=\"./data/restaurants.csv\",method=\"curl\") #where to download data\n",
    "restData <- read.csv(\"./data/restaurants.csv\") #loading the downloaded data\n",
    "\n",
    "head(restData, n=3) #load first 3 rows of the data\n",
    "tail(restData, n=3) #load last 3 rows of the data\n",
    "\n",
    "#overall summary of data\n",
    "summary(restData)\n",
    "str(restData)\n",
    "quantile(restData$councilDistrict,na.rm=TRUE) #quantile of values\n",
    "quantile(restData$councilDistrict,probs=c(0.5, 0.75, 0.9)) #50th is median, 75th is 3rd quarter etc.\n",
    "table(restData$zipCode,useNA=\"ifany\") #use NA if any = if there are missing values, store them seperately\n",
    "table(restData$councilDistrict,restData$zipCode) #two dimensional matrix of two variables\n",
    "\n",
    "#check for missing values\n",
    "sum(is.na(restData$councilDistrict )) #total missing values\n",
    "any(is.na(restData$councilDistrict)) #if there are any missing values\n",
    "all(restData$zipCode > 0) #if everysingle values satisfies the condition or not\n",
    "\n",
    "#row and column sums\n",
    "colSums(is.na(restData)) #colSums and rowSums, gives back sum of NA values for each column\n",
    "all(colSums(is.na(restData))==0) #if all colSums for NA values are 0 or not, returns boolean\n",
    "\n",
    "#values with specific characteristics\n",
    "table(restData$zipCode %in% c(\"what to look for\")) #are there any \"searched\" values in zipCode column\n",
    "table(restData$zipCode %in% c(\"21212\", \"21213\")) #search if there are one or the other value in the column\n",
    "restData[restData$zipCode %in% c(\"21212\", \"21213\"),]#returns subsetted dataset with the rows where value\n",
    "                                                    #in zipCode column is \"21212\" or \"21213\", for all columns\n",
    "\n",
    "#cross tabs\n",
    "data(UCBAdmission) #load R dataset\n",
    "DF = as.data.frame(UCBAdmissions) #create data frame\n",
    "summary(DF) #summary of the data\n",
    "\n",
    "xt <- xtabs(Freq ~ Gender + Admit, data=DF) #Freq is the data you want to show in table, you can break the shown data in multiple variables\n",
    "                                            #+ that'll be shown in a multiple dimensional matrix (gender and admission status here)\n",
    "\n",
    "#Flat tables - cross tabs with multiple variables\n",
    "wrapbreaks$replicate <- rep(1:9, len=54) #warpbreaks is another standard R dataset, replicate variable is added, to make total variable number 3\n",
    "xt = xtabs(breaks ~., data=warpbreaks) #the value that'll appear in table is breaks, this will be broken by all variables through \".\"\n",
    "\n",
    "#output above will be hard to understand because of multiple tables, Flat Tables can help us understand it\n",
    "ftable(xt) #will summarize the data in a compact form\n",
    "\n",
    "#Size of a data set\n",
    "fakeData = rnorm(1e5)\n",
    "object.size(fakeData)\n",
    "print(object.size(fakeData),units=\"Mb\") #size in Mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4a2c2",
   "metadata": {},
   "source": [
    "### Creating New Variables\n",
    "Often, raw data won't have a variable in need, transformation will be needed to create that variable. They'll usually be added to the data frame.\n",
    "Common variables include:\n",
    "- Missingness indicator\n",
    "- Cutting up quantitative variables into factor values\n",
    "- Applying transforms\n",
    "\n",
    "Categorical variable: all values belong to fixed groups.\n",
    "\n",
    "Factor variable: numeric or string categorical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80519f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!file.exists(\"./data\")){dir.create(\"./data\")} #if directory doesn't exist, create a directory\n",
    "fileURL <- \"file URL.csv?accessType=DOWNLOAD\" #check the URL, create connection\n",
    "download.file(fileUrl,destfile=\"./data/restaurants.csv\",method=\"curl\") #where to download data\n",
    "restData <- read.csv(\"./data/restaurants.csv\") #loading the downloaded data\n",
    "\n",
    "s1 <- seq(1,10,by=2); s1 #sequence is used to index different operations on data. We specify the min value, max value.\n",
    "                        #There are two ways to specify how many values to generate.\n",
    "                        #One is by, which starts with min value and increments by 2.\n",
    "s2 <- seq(1,10,length=3) #Another is length, which'll start at min, end at max, and create 3 equally spaced values.\n",
    "\n",
    "x <- c(1,3,8,25,100); seq(along = x) #Yet another way is to use seq(along=\"data\") that creates indices of same length.\n",
    "\n",
    "#Subsetting variables\n",
    "restData$nearMe = restData$neighborhood %in% c(\"Roadland Park\",\"Homeland\") #assign to data frame a new variable, that continues rows with specific values\n",
    "table(restData$nearMe)\n",
    "\n",
    "#creating binary variables\n",
    "restData$zipWrong = ifelse(restData$zipCode <0, TRUE, FALSE) #assign TRUE if zipCode is less than 0, else FALSE\n",
    "table(restData$zipWrong,restData$zipCode < 0) #show a table where whether zipcode is wrong and whether the zip code is less than zero (Less than Zero will be TRUE-TRUE)\n",
    "\n",
    "\n",
    "#Creating categorical variables\n",
    "restData$zipGroups = cut(restData$zipCode,breaks=quantile(restData$zipCode)) #cut (value to cut, cutting parameter) the zipcode data into quantiles\n",
    "table(restData$zipGroups) #categorical factor variables - 0-25th, 25-50th, 50-75th, 75-100th\n",
    "\n",
    "table(restData$zipGroups, restData$zipCode) #which values lands in which clusters\n",
    "\n",
    "#Easier cutting with Hmisc library\n",
    "#library(Hmisc)\n",
    "restData$zipGroups = cut2(restData$zipCode,g=4) #just mention to cut the data in 4 pieces - it'll find the quantiles and break\n",
    "table(restData$zipGroups)\n",
    "\n",
    "#Creating factor variables\n",
    "restData$zcf = factor(restData$zipCode)\n",
    "restData$zcf(1:10)\n",
    "class(restData$zcf)\n",
    "\n",
    "#Levels of factor variable\n",
    "yesno <- sample(c(\"yes\", \"no\")), size = 10, replace = TRUE) #create a vector of 10 randomly repeated \"yes\" and \"no\"\n",
    "yesnofac <- factor(yesno, levels=c(\"yes\",\"no\")) #turn the vector into factor variable.\n",
    "relevel(yesnofac,ref=\"yes\") #By default, the lowest alphabet is first varialbe, but we can define level order.\n",
    "as.numeric(yesnofac) #to change the factor variables back to numeric variables - it'll assign 1 to lowest variable, then 2, 3...\n",
    "\n",
    "#Cutting produces factor variables\n",
    "library(Hmisc)\n",
    "restData$zipGroups = cut2(restData$zipCode,g=4) #cut the variables into 4 groups\n",
    "table(restData$zipGroups) #the class will be factor variable\n",
    "\n",
    "#Using mutate function\n",
    "library(Hmisc); library(plyr) #cut2 is in Hmisc library, Mutate is in plyr library\n",
    "restData2 = mutate(restData, zipGroups = cut2(zipCode,g=4)) #create a new dataframe restData2,\n",
    "                                                            #and simultaneously create a new variable zipGroups from old dataframe restData,\n",
    "                                                            #and add the new variable with the old dataframe restData\n",
    "table(restData2$zipGroups) #view the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ce64f",
   "metadata": {},
   "source": [
    "### Common transformations\n",
    "- abs(x) #absolute value\n",
    "- sqrt(x) #square root\n",
    "- ceiling(x) #ceiling(3.475) is 4\n",
    "- floor(x) #fllor(3.475) is 3\n",
    "- round(x,digits=n) #round(3.475,digits=2) is 3.48\n",
    "- signif(x,digits=n) #signif(3.475,digits=2) is 3.5\n",
    "- cos(x), sin(x) etc.\n",
    "- log(x) #natural logarithm\n",
    "- log2(x), log10(x) #other common logs\n",
    "- exp(x) exponentiating x\n",
    "\n",
    "\n",
    "### Notes and further reading\n",
    "A tutorial from the developers of plyr http://plyr.had.co.nz/09-user/\n",
    "Andrew Jaffe's R notes on transformation biostat.jhsph.edu/~ajaffe/lec_winterR/Lecture%202.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcf064",
   "metadata": {},
   "source": [
    "### Reshaping data\n",
    "\n",
    "Nice tutorial on reshaping\n",
    "slideshare.net/jeffreybreen/reshaping-data-in-r\n",
    "Good plyr primer - r-bloggers.com/a-quick-primer-on-split-apply-combine-problems/\n",
    "\n",
    "Other important functions:\n",
    "- acast - (like dcast above) for casting multi-dimensional arrays\n",
    "- arrange - for faster reordering without using order() commands\n",
    "- mutate - adding new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5d172",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#library(reshape2) #loading library\n",
    "head(mtcars) #standard dataset of R\n",
    "\n",
    "\n",
    "#Melting data frames\n",
    "mtcars$carname <- rownames(mtcars) #make a vector of car names\n",
    "carMelt <- melt(mtcars, id=c(\"carname\",\"gear\",\"cyl\"),measure.vars=c(\"mpg\",\"hp\")) #define which variables are ID, and which are measure variables with \"melt\" function.\n",
    "head(carMelt,n=3) #this'll create rows against 3 ID groups - carname, gear, cyl; and create a variable column for mpg or hp\n",
    "tail(carMelt,n=3)\n",
    "\n",
    "\n",
    "#casting data frames\n",
    "cylData <- dcast(carMelt, cyl ~ variable) #This'll create a matrix with different cylinder values in row\n",
    "                                        #and variables (mpg and hp in this case) in column values\n",
    "                                        #by default it summarises the variables in count (how many data are there)\n",
    "cylData <- dcast(carMelt, cyl ~ variable, mean) #instead of count, we can get mean values of variables \n",
    "\n",
    "#Averaging values\n",
    "head(InsectSprays) #loading standard dataset of R\n",
    "tapply(InsectSprays$count,InsectSprays$spray,sum) #tapply - I'm gonna apply a function (sum) along a column (InsectSprays$count), along identifier (InsectSpray$spray)\n",
    "\n",
    "#Another way to average values\n",
    "spIns = split(InsectSprays$count, InsectSprays$spray) #take InsectSprays$count, and split them by each of the different InsectSprays$spray\n",
    "spIns\n",
    "\n",
    "#1 - lapply\n",
    "sprCount = lapply(spIns, sum) #take the sum for each of the seperated spray values - returns list\n",
    "unlist(sprCount) #make a vector from the list\n",
    "\n",
    "#2 - sapply\n",
    "sapply(spIns,sum) #return vector of sums of sprays\n",
    "\n",
    "#3 - with plyr package\n",
    "ddply(InsectSprays,.(spray),summarize,sum=sum(count)) #ddply(data,.(variables we want to summarize), we want to summarize the variable\n",
    "                                                    #the summarization we want is sum of counts)\n",
    "#This can be used to calculate value and apply to each variable.\n",
    "#Lets assume we want to subtract the total count from the actual count\n",
    "spraySums <- ddply(InsectSprays,.(spray),summarize,sum=ave(count,FUN=sum)) #spraySums is of the same length as the original dataset\n",
    "                                    #now I pass it to ave function applied to count, with sum as sub-function\n",
    "                                    #the result will be that, every time A is in the dataset, it'll repeat the sum of all values of A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74497fe",
   "metadata": {},
   "source": [
    "### Continued: dplyr package for managing data frames\n",
    "The deplyr package is specific for dataframes. It's an updated version of plyr package.\n",
    "Loading this package can generate warnings, but it's no issue.\n",
    "\n",
    "Assumptions of deplyr package:\n",
    "- There is one observation per row\n",
    "- Each column represents a field\n",
    "- Primiary implementation will be R\n",
    "- Other implementations, data table package, relational database systems can be used\n",
    "\n",
    "#### dplyr verbs\n",
    "\n",
    "**Select**\n",
    "returns a subset of columns of dataframe.  \n",
    "\n",
    "**Filter**\n",
    "Extract a subset of rows from a data frame based on logical conditions.  \n",
    "\n",
    "**Arrange**\n",
    "reorder rows of a dataframe.  \n",
    "\n",
    "**Rename**\n",
    "Rename variables in a dataframe.  \n",
    "\n",
    "**Mutate**\n",
    "Add new variables/columns or transform existing variables.  \n",
    "\n",
    "**Summarize**\n",
    "Generate summary statistics of different variables in data frame.\n",
    "\n",
    "#### dplyr properties\n",
    "- First argument is a data frame.\n",
    "- Subsequent arguments describe what to do with it.\n",
    "- Columns can be referred without \"$\" operator.\n",
    "- Result is a new dataframe.\n",
    "- Data frames must be properly formatted and annotated (variable names, factor names etc.) for this all to be useful.\n",
    "\n",
    "Can be used widely (e.g. with data.table, SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb639f",
   "metadata": {},
   "source": [
    "#### dplyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae250689",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "##Select\n",
    "\n",
    "library(dplyr)\n",
    "dataName <- readRDS(\"name.rds\") #can be other file formats\n",
    "dim(dataName)\n",
    "str(dataName)\n",
    "\n",
    "#Getting field names for subsetting columns\n",
    "names(dataName) #returns field names\n",
    "\n",
    "#Selecting multiple columns\n",
    "head(select(dataName,col1:col3)) #returns first 3 columns, which can't be done without dplyr\n",
    "head(select(dataName, -(col1:col3))) #returns all columns except col1 to col3\n",
    "\n",
    "#Doing the same operation without dplyr\n",
    "i <- match(\"colName1\", names(dataName))\n",
    "j <- match(\"colName2\", names(dataName))\n",
    "head(dataName[,-(i:j)]) #which requires extra code\n",
    "\n",
    "\n",
    "##Filter\n",
    "subsetData1 <- filter(dataName, colN > 10) #creating filter to take rows wtih colN values greater than 10\n",
    "subsetData2 <- filter(dataName, col1 > 10 & col2 < 20) #filter with multiple arguments\n",
    "\n",
    "\n",
    "##Arrange\n",
    "dataName <- arrange(dataName, colDate) #arrange the data based on date (stored in colDate) with lowest to highest date\n",
    "head(dataName)\n",
    "tail(dataName)\n",
    "\n",
    "dataName <- arrange(dataName, desc(date)) #arrange against dates in descending order (greatest to lowest)\n",
    "\n",
    "\n",
    "##Rename\n",
    "dataName <- rename(dataName, newCol1Name = oldCol1Name, newCol2Name = oldCol2Name)\n",
    "head(dataName)\n",
    "\n",
    "\n",
    "##Mutate - to create new variable and adding them to data frame\n",
    "dataName <- mutate(dataName, newCol = col1-mean(col1, na.rm=TRUE)) #create a new column, which is old values of col1 - mean value of col1\n",
    "head(select(dataName, col1, newCol))\n",
    "\n",
    "dataName <- mutate(dataName, newCol2 = factor(1*(col2 > 100), labels = c(\"Yes\", \"No\"))) #create a new field and append to dataframe\n",
    "                                                                                        #\"NO\" if value of a row-cell of col2 is greater than 100, else \"Yes\"\n",
    "dataGroup1 <- group_by(dataName, newCol2)\n",
    "dataGroup1\n",
    "\n",
    "summarize(datagroup1, col1 = mean(col1, na.rm = TRUE), col2 = max(col2), col3 = median(col3)) #I want to know what the mean of col1 for \"Yes\" and \"No\", similarly for col2 and 3.\n",
    "\n",
    "dataName <- mutate(dataName, year=as.POSIXlt(colDate)$year + 1900) #similarly, we can take summary over years\n",
    "years <- group_by(dataName, year)\n",
    "summarize(years, col1 = mean(col1, na.rm = TRUE), col2 = max(col2), col3 = median(col3))\n",
    "\n",
    "# %>% (Pipeline) Operator\n",
    "dataName %>% mutate(month = as.POSIXlt(date)$colMonth + 1) %>% group_by(month) %>% summarize(col1 = mean(col1, na.rm = TRUE), col2 = max(col2), col3 = median(oldColName3))\n",
    "#here, output of one operation is fed to next operation via pipeline operator. It allows you to not use many temporary variables, and it's possible to chain related operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8843128",
   "metadata": {},
   "source": [
    "### Merging data\n",
    "- R data merging page: statmethods.net/management/merging.html\n",
    "- plyr information\n",
    "- Types of joins: wikipedia Join_(SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e8469",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!file.exists(\"./data\")){dir.create(\"./data\")} #create directory if doesn't exist\n",
    "fileUrl1 = \"URL.csv\" #URL of file 1\n",
    "fileUrl2 = \"URL.csv\" #URL of file 2\n",
    "download.file(fileUrl1,destfile=\"./data/file1.csv\",method=\"curl\") #download file 1\n",
    "download.file(fileUrl2,destfile=\"./data/file2.csv\",method=\"curl\") #download file 2\n",
    "data1 = read.csv(\"./data/file1.csv\"); data2 <- read.csv(\"./data/file2\") #read the files\n",
    "head(file1,2) #load first 2 rows of file 1\n",
    "head(file2,2) #load first 2 rows of file 2\n",
    "\n",
    "#Merging two datasets that share a common ID with merge()\n",
    "#important parameters: x, y, by, by.x, by.y, \n",
    "#all (by default it'll try to merge by all columns with common names)\n",
    "\n",
    "mergedData = merge(file1, file2, by.x=\"file1CommonID\",by.y=\"file2CommonID\",all=TRUE)\n",
    "#all=TRUE means if there are missing values in one against other, it should include them with NA values\n",
    "\n",
    "head(mergedData)\n",
    "\n",
    "intersect(names(file1), names(file2)) #check which field names of file1 and 2 are similar, since they can be used for merging\n",
    "\n",
    "mergedData2 = merge(file1, file2, all=TRUE) #it'll try to merge against all columns with same name\n",
    "#since many data won't match directly, it can end up adding all rows of both files in the merged file\n",
    "\n",
    "#Joining with plyr package\n",
    "df1 = data.frame(id=sample(1:10), x=rnorm(10)) #data frame of two columns, first one is sampled from 1 to 10, second one is 10 random number\n",
    "df2 = data.frame(id=sample(1:10), y=rnorm(10)) #same as previous\n",
    "arrange(join(df1, df2), id) #plyr can only merge identically named columns automatically. It arranges the data by increasing order of 'id'.\n",
    "\n",
    "df3 = data.frame(id=sample(1:10),z=rnorm(10))\n",
    "dfList = list(df1, df2, df3)\n",
    "join_all(dfList) #it's simpler to join multiple dataframes with plyr's \"join_all\" command, that merges based on common variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c738b39f",
   "metadata": {},
   "source": [
    "## Editing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be0adf9",
   "metadata": {},
   "source": [
    "### Editing text variables\n",
    "How to edit texts to get make them tidy.\n",
    "\n",
    "Names of variables should be:\n",
    "- ALl lower case when possible\n",
    "- Descriptive (diagnosis versus Dx)\n",
    "- Non duplicated\n",
    "- Not have underscores, dots or white spaces\n",
    "\n",
    "Variables with character values\n",
    "- Should usually be made factor variables\n",
    "- Should be descriptive (should be TRUE/FALSE instead of 1/0 and Male/Female instead of M/F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e8dc5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tolower(names(fileName)) #make all field names lower case\n",
    "toupper(names(filename)) #make all field names upper case\n",
    "\n",
    "splitNames = strsplit(names(fileName),\"\\\\.\") #split the column names where there is a \".\". As \".\" is a reserved character, we had to use \"\\\\\".\n",
    "\n",
    "#revise - lists\n",
    "mylist <- list(letters = c(\"A\", \"b\", \"c\"), numbers = 1:3, matrix(1:25, ncol =5))\n",
    "head(mylist)\n",
    "mylist[1] #will return the first element - letters\n",
    "mylist$letters #will return the element named \"letters\"\n",
    "mylist[[1]] #will return the sequence of first element\n",
    "\n",
    "#in the data, if the field with \".\" in name is 6th element\n",
    "splitNames[[6]][1] #will return the first element (before \".\") of 6th element\n",
    "\n",
    "firstElement <- function(x){x[1]} #select first element\n",
    "sapply(splitNames,firstElement) #split names, select first elements\n",
    "\n",
    "#Substitute - sub()\n",
    "sub(\"_\",\"\",names(fileName),) #substitute \"_\" with (blank) \"\" in field names\n",
    "gsub(\"_\",\"\",stringName) #gsub substitutes multiple elements from a string\n",
    "\n",
    "#Search strings\n",
    "grep(\"searchString\",fileName$colName) #will return element positions\n",
    "grep(\"searchString\",fileName$colName, value=TRUE) #will return elements\n",
    "\n",
    "length(grep(\"searchString\",fileName$colName)) #if the lengh is \"0\", that means search result is \"0\"\n",
    "\n",
    "table(grepl(\"searchString\"),fileName$colName) #will return a vector with TRUE(matches), and FLASE(non-matches) values\n",
    "\n",
    "dataName2 <- dataName[!grepl(\"searchString,fileName$colName\"),] #subset data if \"searchString\" doesn't appear\n",
    "\n",
    "#stringr library\n",
    "library(stringr)\n",
    "\n",
    "nchar(\"Sunzid Hassan\") #returns the number of characters in provided string\n",
    "\n",
    "substr(\"Sunzid Hassan\", 1, 6) #will return 1st to 7th letter\n",
    "\n",
    "paste(\"Sunzid\", \"Hassan\") #will return 1 string seperated by space, seperation can be set.\n",
    "\n",
    "paste0(\"Sunzid\", \"Hassan\") #will return 1 string without space\n",
    "\n",
    "str_trim(\"Sunzid    \") #will trim of excess spaces at the beginning or end of string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6f4b0",
   "metadata": {},
   "source": [
    "### Regular Expressions\n",
    "\n",
    "Can be thought of as a combination of literals (e.g. actual words) and matacharacters (e.g. that allows us to search).\n",
    "\n",
    "**^ - start of line**  \n",
    "^I think #will return lines that starts with \"I think\", but not if it's in the middle or end.\n",
    "morning$ #will return lines that ends with mornings, but not if it starts with or contains in middle.\n",
    "\n",
    "**[ ]**  \n",
    "[Bb] #will return match for either upper or lower case\n",
    "^[Ii] am #will return both \"I am\" and \"i am\" at start.\n",
    "\n",
    "**Search for range**  \n",
    "^[0-9][a-zA-Z] #returns if line starts with these. Here, it'll search for numbers, followed by any letter.\n",
    "[^?.]$ #\"^\" here indicates anything that doesn't have a \"?\" or \".\" at the end of the line.\n",
    "\n",
    "**\".\"**  \n",
    "can be used to represent any character\n",
    "9.11 will match all with 9 (any character) 11.\n",
    "\n",
    "**|** or metacharacter  \n",
    "flood|fire will return both floor or fire.\n",
    "flood|earthquake|hurricane will return many matches.\n",
    "\n",
    "^[Gg]ood|[Bb]ad searches for Good/good at first, or Bad/bad anywhere in the line.\n",
    "\n",
    "^([Gg]ood|[Bb]ad) Good/good/Bad/bad at beginning of the line.\n",
    "\n",
    "[Gg]eorge( [Ww]\\.)? [Bb]ush  \n",
    "Question mark after parenthesis indicates the part is optional. So there can or can't be W/w. in the middle of G/george B/bush.\n",
    "Adding \\ before . means it's literal \".\", and not a metacharacter.\n",
    "\n",
    "*** and +**  \n",
    "Indicates Repetation. \"*\" means any number, including none of the item, and + means at least one of the item.\n",
    "\n",
    "(.*) will return any character between parenthesis repeated any number of times, or parenthesis with nothing inside it.\n",
    "\n",
    "[0-9]+(.*)[0-9]+ will look for at least one number [0-9]+, then any/nothing in between (.*), and then at least one number again [0-9]+.\n",
    "\n",
    "**{}** interval quantifier  \n",
    "Min and max number of matches of an expression.\n",
    "[Bb]ush( +[^ ]+ +){1,5} debate  \n",
    "B/bush at first, then -  \n",
    "\"( +\" indicates at least one space after that, followed by \"[^ ]+\" which indicates something that's not a space, followed by \" +)\" which is at least 1 space  -\n",
    "{1,5} this entire space-word-space will be repeated 1 to 5 times.\n",
    "\n",
    "{m,n} means at least m times, but not more than n times.\n",
    "{m} means exactly m matches.\n",
    "{m,} means at least m matches.\n",
    "\n",
    "In addition to limiting scope of alternatives divided by \"|\", parenthesis remember text matches by subexpression enclosed.\n",
    "We refer to the matched text with \\1, \\2 etc.\n",
    "\n",
    " +([a-zA-Z]+) +\\1 +  \n",
    " It'll search \" +\" space, then at least one upper or lower case character, then at least one \" +\" space, then exact match as the part within parenthesis \"\\1\", then at least one \" +\" space.\n",
    " \n",
    "The * is greedy, so it matches the longest possible string that satisfies original expression.\n",
    " \n",
    "^s(.*)s will return multiple words if they start fand end with s, instead of one word.\n",
    "\n",
    "^s(.*?)s$ is not greedy, as *? searches for smaller number of matches, with s$ at last.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825a56d",
   "metadata": {},
   "source": [
    "### Working with dates\n",
    "\n",
    "Abbreviation:\n",
    "%d = day as number (0-31)\n",
    "%a = abbreviated weekday\n",
    "%A = unabbreviated weekday\n",
    "%m = month (00-12)\n",
    "%b = abbreviated month\n",
    "%B = unabbreviated month\n",
    "%y = 2 digit year\n",
    "%Y = four digit year\n",
    "\n",
    "Tutorial:\n",
    "r-statistics.com/2012/do-more-with-dates-and-times-in-r-with-lubridate-1-1-0/\n",
    "\n",
    "Class POSIXlt and POSIXct with ?POSIXlt or ?POSIXct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453030d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "d1 = date() #returns current date and time of class \"character\"\n",
    "d1\n",
    "\n",
    "d2 = Sys.Date() #returns just date of class \"date\". Howver, working with date format can be tricky.\n",
    "d2\n",
    "\n",
    "format(d2, \"%a %b %d\") #change date formating\n",
    "\n",
    "#as.date()\n",
    "x = c(\"1jan1960\", \"2jan1960\", \"31mar1960\", \"30jul1960\"); z = as.Date(x,\"%d%b%Y\") #format string as date\n",
    "z\n",
    "z[1] - z[2] #difference of two days\n",
    "as.numeric(z[1]-z[2]) #numeric difference of 2 dates\n",
    "\n",
    "#Converting to Julian\n",
    "weekdays(d2) #returns weekday of the provided date\n",
    "months(d2)\n",
    "julian(d2) #number of days since origin (1970-01-01)\n",
    "\n",
    "#Lubridate package\n",
    "library(lubridate); ymd(\"20130108\") #year-month-date ymd command will format the input as date without any extra argument\n",
    "mdy(\"08/04/2013\")\n",
    "dmy(\"03-04-2013\")\n",
    "\n",
    "#Dealing with times\n",
    "ymd_hms(\"2011-08-03 10:15:03\") #date and time formatting\n",
    "\n",
    "Sys.timezone(location = TRUE)\n",
    "OlsonNames(tzdir = NULL) #thi'll return time zone\n",
    "\n",
    "ymd_hms(\"2011-08-03 10:15:03\", tz=\"Asia/Dhaka\")\n",
    "\n",
    "#Some function have slightly different syntax\n",
    "x = c(\"1jan1960\", \"2jan1960\", \"31mar1960\", \"30jul1960\"); z = as.Date(x,\"%d%b%Y\") #format string as date\n",
    "wday(x[1]) #returns day in number, instead of weekdays() in base R\n",
    "wday(x[1], label=TRUE) #returns day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624be8a",
   "metadata": {},
   "source": [
    "### Data resources\n",
    "Open goverment sites that contains data:\n",
    "- UN - data.un.org\n",
    "- US - data.gov\n",
    "- UK - data.gov.uk\n",
    "- France - data.gouv.fr\n",
    "- Ghana - data.gov.gh\n",
    "- Australia - data.gov.au\n",
    "- Germany - govdata.de\n",
    "- Hong Kong - gov.hk/en/theme/psi/datasets\n",
    "- Japan - data.go.jp\n",
    "- Many more - data.gov/opendatasites\n",
    "\n",
    "Data on human health - gapminder.org\n",
    "- US Survey data - asdfree.com\n",
    "- Infochimps marketplace - infochimps.com/marketplace\n",
    "- Kaggle data - kaggle.com\n",
    "\n",
    "Collections by data scientists\n",
    "- Hilary Mason http://bitly.com/bundles/hmason/1\n",
    "-Peter Skomoroch https://delicious.com/pskomoroch/dataset\n",
    "- Jeff Hammerbacher http://www.quoro.com/Jeff-Hammerbacher/Introduction-to-Data-Science-Data-Sets\n",
    "- Gregory Piatetsky-Shapiro http://www.kdnuggets.com/gps.html\n",
    "\n",
    "- http://blog.mortardata.com/post/67652898761/6-dataset-lists-curated-by-data-scientists\n",
    "\n",
    "More specialized collections\n",
    "- Stanford large network data\n",
    "- UCI machine learning\n",
    "- KDD Nudgets dataset\n",
    "- CMU statlib\n",
    "- Gene expression omnibus\n",
    "- ArXiv data\n",
    "- Public data sets on amazon web services\n",
    "\n",
    "Some APIs with R interfaces\n",
    "- Twitter and twitterR package\n",
    "- figshare and rfigshare\n",
    "- PLoS and rplos\n",
    "- rOpenSci\n",
    "- Facebook and RFacebook\n",
    "- Google maps and RGoogleMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f965d",
   "metadata": {},
   "source": [
    "# Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d15bb2a",
   "metadata": {},
   "source": [
    "## Probability and Expected Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf047e",
   "metadata": {},
   "source": [
    "### Statistical Inference\n",
    "Generating conclusion about a population from a noisy sample.\n",
    "\n",
    "### Probability\n",
    "Given a random experiment, a probability measure is a population quantity that summarizes the randomness. Probability is a character of population, which is predicted from sample.\n",
    "\n",
    "#### Probability mass functions\n",
    "Random variable can be discrete (e.g. dice roll, coin toss, possible web site traffic on a given day), or continuous( - expressed with range).\n",
    "Probability mass function takes discrete outcome value as input, and outputs probability. Sum of probability of all discrete outcome is 1.\n",
    "If we flip a coin, probability of head is P(H) = (.5)^(1-1)*(.5)^(1-0) = 0.5\n",
    "\n",
    "#### Probability density function\n",
    "Associated with continuous random variables. The rules are similar - total area under it must be 1, vlaue must be greater than or equal to 0 everywhere.  \n",
    "The function is bell shaped for normally distributed data.\n",
    "Area under a variable expresses the probability of that variable (e.g. probability of IQ between 100 and 110, when mean is 100, and standard deviation is 10). Again probability is an attribute of population, we use data to evaluate our estimation of probability.\n",
    "\n",
    "We can take simpler density function (e.g., a right triangle), but the area needs to be 1.\n",
    "\n",
    "##### Cumulative distribution function and survival function\n",
    "Cumulative value is value till the point (area under function till value of 110 IQ from LHS). Survival function is area from RHS, or 1-Area from LHS.\n",
    "\n",
    "##### Quantiles\n",
    "95th percentile - distribute all in ascending order, which point is above 95% of observation. Percentile is quantile, excpet it's expressed with percentage instead of proportion. Median is 50th percentile.\n",
    "If we pick a point from a distribution, the probability that the value will be less than 95th percentile value is 95%, and it'll be greater than is 5%.\n",
    "Population median is estimand, sample median is estimator. Statistical inference links sample to population.\n",
    "\n",
    "### Conditional Probability\n",
    "P(A|B) = P(A AND B)/P(B)\n",
    "\n",
    "#### Baye's rule\n",
    "Determining P(A|B) from P(B|A), with some extra information.\n",
    "\"+\" the test says the person has disease.\n",
    "\"-\" the test says the person don't have the disease.\n",
    "D the person actually has the disease.\n",
    "Dc the person don't have the disease.\n",
    "\n",
    "Sensitivity = P(+|D); probability that the test will be positive given the person actually has the disease.\n",
    "Specificity = P(-|Dc); probability that the test will be negative given the person don't have the disease.\n",
    "\n",
    "In absence of a test, probability of having disease is the Prevalence of a disease = P(D)\n",
    "Positive predictive value = P(D|+)\n",
    "Negative predictive value = P(Dc|-)\n",
    "\n",
    "Example:\n",
    "A test has -\n",
    "Sensitivity of 99.7%\n",
    "Specificity of 98.5%\n",
    "Prevalance of disease is 0.1% of population.\n",
    "What is positive predictive value P(D|+)\n",
    "\n",
    "Using Baye's formula:\n",
    "P(D|+)= \n",
    "\n",
    "$P(D|+) = {(P(+|D)P(D)\\over P(+|D)P(D)+P(+|Dc)P(Dc))}$\n",
    "\n",
    "$P(D|+) = {(P(+|D)P(D)\\over P(+|D)P(D)+(1-P(-|Dc))(1-P(D))}$\n",
    "\n",
    "$P(D|+) = {Sensitivity \\times Prevalence\\over Sensitivity \\times Prevalence +(1-Specificity) \\times (1-Prevalence)}$\n",
    "\n",
    "$=.062$\n",
    "\n",
    "Even after getting diagnosed with Positive, there is just 6% chance that the person is actually positive!\n",
    "\n",
    "Similarly,\n",
    "\n",
    "$P(Dc|+) = {(P(+|Dc)P(Dc)\\over P(+|D)P(D)+P(+|Dc)P(Dc)}$\n",
    "\n",
    "#### Likelihood ratios\n",
    "\n",
    "${P(D|+) \\over P(Dc|+)} = {(P(+|D) \\over P(+|Dc)} \\times {P(D) \\over P(Dc)}$\n",
    "\n",
    "${P(D|+) \\over P(Dc|+)}$\n",
    "Odds of disease given a positive test result.\n",
    "\n",
    "${P(D) \\over P(Dc)}$\n",
    "Odds of disease in the absence of a test result.\n",
    "\n",
    "${P(+|D) \\over P(+|Dc)}$\n",
    "Diagnostic likelihood ratio for a positive test result.\n",
    "\n",
    "$post-test odds of disease = diagnostic likelihood ratio \\times pre-test odds of disease$\n",
    "\n",
    "In case of diagnostic case above\n",
    "$DLR = .997/(1-.985) = 66$\n",
    "In other words, the hypothesis of getting disease is 66 times more supported by the data, regardless of the pre-test odds of disease, then the hypothesis of no disease.\n",
    "\n",
    "Given negative rest result.\n",
    "\n",
    "Specificity 98.5%, sensitivity 99.7%.\n",
    "DLR- = (1-.997)/.985 = .003\n",
    "In other words, given negative test result, the hypothesis of not getting disease is .003 times supported by the data.\n",
    "\n",
    "#### Independence\n",
    "Event A is independent of event B if,  \n",
    "P(A|B) = P(A) where P(B) > 0.  \n",
    "P(A$\\cap$B) = P(A)P(B)\n",
    "\n",
    "We can't just multiply probabilities to calculate joint probabilities, because they might not be independent.\n",
    "\n",
    "IID - Independent and Identically Distributed (all drawn from same population distribution) random variables.\n",
    "\n",
    "### Expected values\n",
    "Expected values (sample mean and variance) is used to estimate population expected values (mean and variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168cd519",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pbeta(c(.4, .5), 2, 1) #beta is a right triangle density. 2 is the height, 1 is base, area is 1.\n",
    "#.4 and .5 is the probability at 40% and 50% of independent variables.\n",
    "\n",
    "pnorm() #for normal distribution\n",
    "\n",
    "#q means quantile\n",
    "qbeta(0.5, 2, 1) #50th quantile of beta distribution where height = 2, base = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef6922",
   "metadata": {},
   "source": [
    "## Variability, Distribution and Asymptotics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761ad99",
   "metadata": {},
   "source": [
    "## Intervals, Testing and Pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9740d4df",
   "metadata": {},
   "source": [
    "## Power, Bootstrapping and Permutation Tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
